{
  "hash": "49079267ec7819e8f18e6a388506fefd",
  "result": {
    "markdown": "---\ntitle: \"Decline of Big Tech Stock\"\nauthor: \"Parker Barnes\"\ndate: \"2023-02-09\"\n---\n\n\n![](big_tech.jpg)\n\nWelcome to my very first #tidytuesday blog post! In this post I will showcase the new [per-operation grouping](https://www.tidyverse.org/blog/2023/02/dplyr-1-1-0-per-operation-grouping/) functionality released in dplyr 1.1.0. I also want to demonstrate one of my favorite lesser-known dplyr tricks!\n\nFor this analysis, we'll explore [this week's tidytuesday data set](https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-02-07/readme.md) consisting of daily big tech stock prices from 2010-2022.\n\nFirst, let's download the data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nbig_tech_stock_prices <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-07/big_tech_stock_prices.csv')\nbig_tech_companies <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-07/big_tech_companies.csv')\n\nbig_tech_stock_prices |> glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 45,088\nColumns: 8\n$ stock_symbol <chr> \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"AAPL\", \"…\n$ date         <date> 2010-01-04, 2010-01-05, 2010-01-06, 2010-01-07, 2010-01-…\n$ open         <dbl> 7.622500, 7.664286, 7.656429, 7.562500, 7.510714, 7.60000…\n$ high         <dbl> 7.660714, 7.699643, 7.686786, 7.571429, 7.571429, 7.60714…\n$ low          <dbl> 7.585000, 7.616071, 7.526786, 7.466071, 7.466429, 7.44464…\n$ close        <dbl> 7.643214, 7.656429, 7.534643, 7.520714, 7.570714, 7.50392…\n$ adj_close    <dbl> 6.515213, 6.526476, 6.422664, 6.410790, 6.453412, 6.39648…\n$ volume       <dbl> 493729600, 601904800, 552160000, 477131200, 447610800, 46…\n```\n:::\n\n```{.r .cell-code}\nbig_tech_stock_prices |> \n  count(stock_symbol) |> \n  inner_join(big_tech_companies) |> \n  select(company, stock_symbol, n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 14 × 3\n   company                                     stock_symbol     n\n   <chr>                                       <chr>        <int>\n 1 Apple Inc.                                  AAPL          3271\n 2 Adobe Inc.                                  ADBE          3271\n 3 Amazon.com, Inc.                            AMZN          3271\n 4 Salesforce, Inc.                            CRM           3271\n 5 Cisco Systems, Inc.                         CSCO          3271\n 6 Alphabet Inc.                               GOOGL         3271\n 7 International Business Machines Corporation IBM           3271\n 8 Intel Corporation                           INTC          3271\n 9 Meta Platforms, Inc.                        META          2688\n10 Microsoft Corporation                       MSFT          3271\n11 Netflix, Inc.                               NFLX          3271\n12 NVIDIA Corporation                          NVDA          3271\n13 Oracle Corporation                          ORCL          3271\n14 Tesla, Inc.                                 TSLA          3148\n```\n:::\n:::\n\n\nNote: Meta and Tesla did not go public until after Jan 2010, so they have slightly less data.\n\nNow let's visualize the stocks as simple faceted line charts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbig_tech_stock_prices |>\n  ggplot(aes(date, adj_close)) +\n  geom_line() +\n  facet_wrap(~stock_symbol, ncol = 4, scales = \"free_y\") +\n  labs(x = NULL, y = NULL)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nWith the exception of IBM, each stock peaks around the end of 2021, and then declines thereafter.\n\nLet's zoom in on the peaks by plotting them on the same axes. Here we will use the new `by` argument to find the maximum `adj_close` for each `stock_symbol`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbig_tech_stock_prices |> \n  filter(stock_symbol != \"IBM\") |> \n  slice_max(adj_close, by = stock_symbol) |> \n  ggplot(aes(date, adj_close, color = stock_symbol)) +\n  geom_point() +\n  ggrepel::geom_text_repel(aes(label = stock_symbol), size = 3, vjust = -.75) +\n  scale_x_date(labels = scales::label_date_short(), breaks = \"month\") +\n  labs(title = \"Peak Stock Prices\", x = NULL, y = NULL) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nHow steep of a decline do these stocks see in the weeks and months following their peak? How do they compare to each other?\n\nTo answer this question, we will need to filter each stock to include only the data following its peak. This may seem trivial at first, but it's a bit trickier than you might think. Since each stock reaches its peak at a different point, we can't simply filter the whole data set by a single value.\n\nOne approach would be to make a separate tibble containing just the max price dates, join it back with the original, and filter the dates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeak_price_dates <- \n  big_tech_stock_prices |> \n  slice_max(adj_close, by = stock_symbol) |> \n  select(stock_symbol, peak_date = date, peak_price = adj_close)\n\nbig_tech_stock_prices |> \n  inner_join(peak_price_dates) |> \n  filter(date >= peak_date) |> \n  # for demonstration purposes\n  slice_min(date, n = 3, by = stock_symbol) |> \n  select(stock_symbol, date, adj_close)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 42 × 3\n   stock_symbol date       adj_close\n   <chr>        <date>         <dbl>\n 1 AAPL         2022-01-03      181.\n 2 AAPL         2022-01-04      179.\n 3 AAPL         2022-01-05      174.\n 4 ADBE         2021-11-19      688.\n 5 ADBE         2021-11-22      674.\n 6 ADBE         2021-11-23      665.\n 7 AMZN         2021-07-08      187.\n 8 AMZN         2021-07-09      186.\n 9 AMZN         2021-07-12      186.\n10 CRM          2021-11-08      310.\n# ℹ 32 more rows\n```\n:::\n:::\n\n\nThis solution works, but there's a better (in my opinion) way that doesn't require a separate tibble. The method is derived from a base-R concept called *subsetting*.\n\nSubsetting can be used to filter a vector or dataframe by some condition, much like `dplyr::filter`. Instead of a function call, we use square brackets (`[]`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvec <- 0:20\n# subset to get even numbers\nvec[vec %% 2 == 0]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  0  2  4  6  8 10 12 14 16 18 20\n```\n:::\n\n```{.r .cell-code}\n# subset to get rows with mpg > 21\nmtcars[mtcars$mpg > 21,]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nDatsun 710     22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nMerc 240D      24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230       22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFiat X1-9      27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n```\n:::\n:::\n\n\nIn dplyr, we can apply this same principle by combining a `filter` with a subset. For our case, we combine `filter`, subset, and `which.max`. Coupled with per-operation grouping, we can accomplish the entire process in a single step!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstock_downfalls <- \n  big_tech_stock_prices |>\n  # filter date by the grouped and subsetted date\n  filter(date >= date[which.max(adj_close)], .by = stock_symbol)\n\nstock_downfalls |> \n  ggplot(aes(date, adj_close, color = stock_symbol)) +\n  geom_line() +\n  ggrepel::geom_label_repel(aes(peak_date, peak_price, label = stock_symbol), data = peak_price_dates, size = 3) +\n  scale_x_date(labels = scales::label_date_short(), breaks = \"month\") +\n  labs(x = NULL, y = NULL) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nNow we can clearly see which stocks endured more dramatic price dips and how they fared over the following 1-2 years.\n\nThank you so much for reading and I hope this exercise was useful. Please reach out if you have any questions or feedback!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}